{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01eb3647-21b6-4e87-a25d-a47bd55de7b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, DoubleType,TimestampType\n",
    "import datetime\n",
    "\n",
    "# Create Spark session\n",
    "#spark = SparkSession.builder.appName(\"ContractsDF\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"contract_name\", StringType(), True),\n",
    "    StructField(\"client_name\", StringType(), True),\n",
    "    StructField(\"start_date\", DateType(), True),\n",
    "    StructField(\"end_date\", DateType(), True),\n",
    "    StructField(\"contract_value\", DoubleType(), True),\n",
    "    StructField(\"status\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (10 records)\n",
    "data = [\n",
    "    (1, \"Contract A\", \"Client X\", datetime.date(2024, 1, 1), datetime.date(2025, 1, 1), 50000.0, \"Active\"),\n",
    "    (2, \"Contract B\", \"Client Y\", datetime.date(2023, 6, 15), datetime.date(2024, 6, 14), 75000.0, \"Expired\"),\n",
    "    (3, \"Contract C\", \"Client Z\", datetime.date(2024, 3, 10), datetime.date(2026, 3, 9), 120000.0, \"Active\"),\n",
    "    (4, \"Contract D\", \"Client A\", datetime.date(2022, 11, 1), datetime.date(2023, 11, 1), 40000.0, \"Expired\"),\n",
    "    (5, \"Contract E\", \"Client B\", datetime.date(2025, 5, 1), datetime.date(2026, 5, 1), 95000.0, \"Pending\"),\n",
    "    (6, \"Contract F\", \"Client C\", datetime.date(2024, 7, 20), datetime.date(2027, 7, 19), 200000.0, \"Active\"),\n",
    "    (7, \"Contract G\", \"Client D\", datetime.date(2023, 9, 1), datetime.date(2024, 8, 31), 67000.0, \"Expired\"),\n",
    "    (8, \"Contract H\", \"Client E\", datetime.date(2024, 2, 5), datetime.date(2025, 2, 4), 88000.0, \"Active\"),\n",
    "    (9, \"Contract I\", \"Client F\", datetime.date(2022, 4, 10), datetime.date(2023, 4, 10), 30000.0, \"Expired\"),\n",
    "    (10,\"Contract J\", \"Client G\", datetime.date(2025, 1, 15), datetime.date(2026, 1, 15), 110000.0, \"Pending\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show records\n",
    "#df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ffdaf7-cea7-4388-8253-fa83343fa15b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema2 = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"contract_name\", StringType(), True),\n",
    "    StructField(\"client_name\", StringType(), True),\n",
    "    StructField(\"start_date\", DateType(), True),\n",
    "    StructField(\"end_date\", DateType(), True),\n",
    "    StructField(\"contract_value\", DoubleType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"contract_type\", StringType(), True),\n",
    "    StructField(\"last_updated\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (10 records again, but with 2 extra columns)\n",
    "data2 = [\n",
    "    (11, \"Contract A\", \"Client X\", datetime.date(2024, 1, 1), datetime.date(2025, 1, 1), 50000.0, \"Active\", \"Fixed\", datetime.datetime(2025, 1, 1, 10, 30)),\n",
    "    (12, \"Contract B\", \"Client Y\", datetime.date(2023, 6, 15), datetime.date(2024, 6, 14), 75000.0, \"Expired\", \"Time & Material\", datetime.datetime(2024, 6, 14, 15, 0)),\n",
    "    (13, \"Contract C\", \"Client Z\", datetime.date(2024, 3, 10), datetime.date(2026, 3, 9), 120000.0, \"Active\", \"Retainer\", datetime.datetime(2025, 3, 10, 9, 15)),\n",
    "    (14, \"Contract D\", \"Client A\", datetime.date(2022, 11, 1), datetime.date(2023, 11, 1), 40000.0, \"Expired\", \"Fixed\", datetime.datetime(2023, 11, 1, 17, 45)),\n",
    "    (15, \"Contract E\", \"Client B\", datetime.date(2025, 5, 1), datetime.date(2026, 5, 1), 95000.0, \"Pending\", \"Time & Material\", datetime.datetime(2025, 5, 1, 12, 0)),\n",
    "    (16, \"Contract F\", \"Client C\", datetime.date(2024, 7, 20), datetime.date(2027, 7, 19), 200000.0, \"Active\", \"Retainer\", datetime.datetime(2025, 7, 20, 8, 20)),\n",
    "    (17, \"Contract G\", \"Client D\", datetime.date(2023, 9, 1), datetime.date(2024, 8, 31), 67000.0, \"Expired\", \"Fixed\", datetime.datetime(2024, 8, 31, 18, 10)),\n",
    "    (18, \"Contract H\", \"Client E\", datetime.date(2024, 2, 5), datetime.date(2025, 2, 4), 88000.0, \"Active\", \"Time & Material\", datetime.datetime(2025, 2, 4, 11, 30)),\n",
    "    (19, \"Contract I\", \"Client F\", datetime.date(2022, 4, 10), datetime.date(2023, 4, 10), 30000.0, \"Expired\", \"Fixed\", datetime.datetime(2023, 4, 10, 14, 50)),\n",
    "    (20,\"Contract J\", \"Client G\", datetime.date(2025, 1, 15), datetime.date(2026, 1, 15), 110000.0, \"Pending\", \"Retainer\", datetime.datetime(2025, 1, 15, 16, 40))\n",
    "]\n",
    "\n",
    "# Create new DataFrame\n",
    "df2 = spark.createDataFrame(data2, schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe7074f-a8ee-4a85-97b8-778a5e0366f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema with only 5 columns\n",
    "schema3 = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"contract_name\", StringType(), True),\n",
    "    StructField(\"client_name\", StringType(), True),\n",
    "    StructField(\"contract_value\", DoubleType(), True),\n",
    "    StructField(\"status\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (10 records)\n",
    "data3 = [\n",
    "    (21, \"Contract A\", \"Client X\", 50000.0, \"Active\"),\n",
    "    (22, \"Contract B\", \"Client Y\", 75000.0, \"Expired\"),\n",
    "    (23, \"Contract C\", \"Client Z\", 120000.0, \"Active\"),\n",
    "    (24, \"Contract D\", \"Client A\", 40000.0, \"Expired\"),\n",
    "    (25, \"Contract E\", \"Client B\", 95000.0, \"Pending\"),\n",
    "    (26, \"Contract F\", \"Client C\", 200000.0, \"Active\"),\n",
    "    (27, \"Contract G\", \"Client D\", 67000.0, \"Expired\"),\n",
    "    (28, \"Contract H\", \"Client E\", 88000.0, \"Active\"),\n",
    "    (29, \"Contract I\", \"Client F\", 30000.0, \"Expired\"),\n",
    "    (30,\"Contract J\", \"Client G\", 110000.0, \"Pending\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df3 = spark.createDataFrame(data3, schema3)\n",
    "\n",
    "# Show records\n",
    "#df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c524e342-b552-41bc-be5b-9e0ebc036ae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS bronze.contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a4f2ba-b26c-4252-afe0-ead24743b638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.contracts.contract1\")\n",
    "df2.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.contracts.contract2\")\n",
    "df3.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.contracts.contract3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a1c0f60-ad94-48c0-a86f-c9650be0eb8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final = df.unionByName(df2,allowMissingColumns=True).unionByName(df3,allowMissingColumns=True)\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ee5180-1071-48c0-bdec-27f8d5089952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "if spark.catalog.tableExists(\"bronze.contracts.contract_final\"):\n",
    "    dt = DeltaTable.forName(spark,\"bronze.contracts.contract_final\")\n",
    "    dt.alias(\"dt\").merge(df_final.alias(\"src\"),\"dt.id=src.id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "else:\n",
    "    df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"bronze.contracts.contract_final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b86d37a4-1de1-4e8e-a130-7c9f49794e30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"bronze.contracts.contract_final\")\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6846702597104921,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Practice_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
